{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTJP3h3blcDm"
   },
   "source": [
    "# Recherche d'Information et traitement de donn√©es massives\n",
    "\n",
    "# Lab 4 : Recherche d‚Äôinformation sur le Web "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e3yAdUK5lcDp"
   },
   "source": [
    "\n",
    "L'objectif de cette s√©ance est d'√©tudier le probl√®me de la recherche d'information sur le WEB. Elle constiendra deux parties.\n",
    " + La premi√®re partie s'int√©resse aux approches permettant le passage √† l'√©chelle des donn√©es du WEB et notamment au paradigme MapReduce. Vous pratiquerez notamment dans cette partie l'√©criture d'algorithmes selon le cadre MapReduce.\n",
    " + La deuxi√®me partie s'int√©resse √† la prise en compte de la structure de la collection du WEB au travers de la mise en oeuvre d'approches d'analyse de liens pour l'ordonnancement.\n",
    " + Plusieurs exercices d'approfondissement facultatifs vous sont aussi propos√©s.\n",
    "\n",
    "## PARTIE 1 :  RECHERCHE WEB et PASSAGE √Ä l'ECHELLE\n",
    "## EXERCICES : √©criture d'algorithmes en MapReduce (sur papier)\n",
    "\n",
    "### Avant propos : un bref rappel de MapReduce\n",
    "Comme nous l'avons vu dans le cours 4, Map Reduce est un **mod√®le de programmation** (ou patron de programmation) qui fournit un cadre pour automatiser le calcul distribu√© sur des donn√©es massives. Ce cadre propose d'√©crire tout traitement √† l'aide de deux op√©rations `map` et  `reduce` et de la repr√©sentation des donn√©es sous la forme de paires `(cl√©,valeur)`.\n",
    "MapReduce est aussi un **framework d'ex√©cution** qui permet l'√©x√©cution distribu√©e des programmes √©crits selon ce cadre, et cela de mani√®re totalement transparente selon le sch√©ma rappel√© ci-dessous.\n",
    "\n",
    "\n",
    "<img src=\"./Figures/map-reduce.png\" width=\"500\" height=\"500\" />\n",
    "\n",
    "1.  Un certain nombre de t√¢ches *Map* sont aliment√©es par une ou\n",
    "    plusieurs partitions de donn√©es en provenance d'un syst√®me de\n",
    "    fichiers distribu√©s (par exemple GFS, HDFS, S3).  Ces t√¢ches *Map* transforment ces donn√©es en une s√©quence de paires cl√©s-valeurs. C'est le d√©veloppeur qui d√©termine comment sont calcul√©es les paires\n",
    "    cl√©s-valeurs en fonction des donn√©es en entr√©e en √©crivant le code dans la fonction `map()`.\n",
    "2.  Les paires cl√©s-valeurs sont collect√©es par un contr√¥leur ma√Ætre et tri√©es par cl√©s.\n",
    "    Les paires sont redirig√©es vers les t√¢ches *Reduce* de fa√ßon √† ce que toutes les paires\n",
    "    qui ont la m√™me cl√© soient redirig√©es vers la m√™me t√¢che *Reduce*.\n",
    "3.  Les t√¢ches *Reduce* traitent les cl√©s une par une. Elles agr√®gent/combinent les valeurs associ√©es\n",
    "    aux cl√©s selon le code sp√©cifi√© dans la fonction `reduce()`.\n",
    "\n",
    "\n",
    "\n",
    "Dans le cours, nous avons vu comment √©crire en MapReduce un programme permettant de compter le nombre d'occurences des mots d'une collection donn√©e (programme **WordCount**). C'est une t√¢che qui peut sembler tr√®s simple √† √©crire quand on travaille sur une collection de petite taille. Vous avez d'ailleurs propos√© une solution non-distribu√©e pour cette t√¢che pour la collection TIME (√©tape de filtrage par mots fr√©quents ou calcul de la pond√©ration TF). En python, nous pouvons √©crire cela tr√®s simplement, par exemple comme dans le programme ci-dessous.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uNjiI4lhlcDr"
   },
   "outputs": [],
   "source": [
    "def count_frequency(collection):\n",
    "    tokens_count={}\n",
    "    for doc_id in collection:\n",
    "        for token in collection[doc_id]:\n",
    "            if token in tokens_count.keys():\n",
    "                tokens_count[token] +=1\n",
    "            else:\n",
    "                tokens_count[token]=+1\n",
    "    return tokens_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mCpHF-nmlcDz"
   },
   "source": [
    "Dans le cas o√π l'on consid√®re une grosse collection dont le stokage et les traitements n√©c√©ssitent d'√™tre distribu√©s, alors cette t√¢che devient plus diffile √† √©crire, notamment car il faut prendre en compte la distribution des donn√©es et des traitements. Le mod√®le MapReduce apporte une solution √† cela en proposant d'√©crire ce type de programme selon le principe suivant :\n",
    "\n",
    "+ On consid√®re que le document ou la partie du document est donn√© sous la forme d'une paire (cl√©,valeur) avec comme cl√©, l'identifiant du document et comme valeur le contenu textuel du document.\n",
    "\n",
    "+ √âtant donn√©e une collection d‚Äôitems, appliquer √† chaque item un processus de transformation individuelle (√©tape `MAP`) qui produit des valeurs interm√©diaires √©tiquet√©es. Dans le cas du WordCount, il s'agit juste de prendre chaque token du document ou de la partie du document et de la transformer en la paire (mot,1) comme illustr√© ci-dessous.\n",
    "\n",
    "<img src=\"./Figures/diapositive12.jpg\" width=\"500\" height=\"500\" />\n",
    "\n",
    "\n",
    "+ Regrouper ces valeurs interm√©diaires par √©tiquette (√©tape faite par le framework `SHUFFLE AND SORT`). On aura dans le cas du WordCount en sortie de cette √©tape en ensemble de paires (mot, [1,1,1,1..]) avec comme cl√©s les diff√©rents mots du documents et comme valeur une liste des 1-occurence des mots dans le document consid√©r√©.\n",
    "+ Appliquer une fonction d'agr√©gation √† chaque groupe (√©tape `REDUCE`).Dans le cas du Wordcount il s'agit juste de sommer la liste des occurences comme illustr√© ci-dessous.\n",
    "\n",
    "<img src=\"./Figures/diapositive15.jpg\" width=\"500\" height=\"500\" />\n",
    "\n",
    "\n",
    "### Concevoir un programme selon le cadre MapReduce : un peu de m√©thodologie\n",
    "\n",
    "Pour faciliter l'√©criture de programmes selon le cadre MapReduce, il est souvent n√©cessaire de se poser d'abord  les questions ci-dessous.\n",
    "\n",
    " + De quelle nature sont les documents en entr√©e ? Comment les repr√©senter sous une forme `(cl√©, valeur)` ?\n",
    " + Quelles sont les groupes vis√©s ? Quelles sont les valeurs interm√©diaires que je cherche √† produire depuis mon document d'entr√©e ?\n",
    " + Quelle est la valeur finale ? Quelle est la nature de l'agr√©gation pour produire cette valeur finale ? \n",
    "\n",
    "Une fois les r√©ponses √† ces questions claires, il suffira ensuite :\n",
    " + D'√©crire la fonction de `map` qui prend en entr√©e un document et qui produit une s√©quence de paires `(cl√©, valeur)`.\n",
    " + D'avoir en t√™te que ces diff√©rentes paires sont collect√©es par le framework et tri√©es par cl√©s pour donner une entr√©e √† la t√¢che d'agr√©gation l'ensemble des paires qui ont la m√™me cl√©. \n",
    " + D'√©crire la fonction `reduce` qui prend en entr√©e une paire `(cl√©, liste(valeurs))` en sp√©cifiant le traitement d'agr√©gation voulu. \n",
    "\n",
    "Le sch√©ma d'√©x√©cution et sa trace sur le probl√®me du WordCount vous est donn√© ci-dessous, pour rappel.\n",
    "\n",
    "<img src=\"./Figures/diapositive16.jpg\" width=\"500\" height=\"500\" />\n",
    "\n",
    "<img src=\"./Figures/diapositive17.jpg\" width=\"500\" height=\"500\" />\n",
    "\n",
    "Nous allons maintenant appliquer le cadre MapReduce au calcul de la pond√©ration `TF-IDF`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D07OSBCklcD1"
   },
   "source": [
    "### A votre tour : Tf-IDF en MapReduce\n",
    "\n",
    "L'objectif est de calculer `Tf-IDF` pour un ensemble de documents en utilisant le mod√®le MapReduce. Pour rappel, comme vu dans le cours 1, `Tf-IDF (Term frequency-Inverse Document Frequency)` est une statistique qui traduit le niveau d'importance d'un terme $t$ pour un document $d$ appartenant √† une collection (ou un corpus) de taille $N$. Dans cet exercice, on consid√®rera la formulation math√©matique suivante :\n",
    "\n",
    "$$TF-IDF(t_i,d) = ( \\frac{tf_{t_i,d}}{\\sum_{t_k \\in d} tf_{t_k,d}}  ) \\times \\log \\left( \\frac{N}{df_t}\\right)$$\n",
    "\n",
    "o√π $tf_{t,d}$ est le nombre d'occurrence du terme $t$ dans le document $d$, $N$ le nombre de documents de la collection et $df_t$ le nombre de documents dans lesquels $t$ est pr√©sent.\n",
    "\n",
    "Vous pouvez prendre le temps de regarder la correction du Lab2 dans lequel nous avons propos√© des solutions pour calculer cette statistique sur la collection TIME.\n",
    "\n",
    "Pour calculer cette statistique sur une tr√®s grosse collection de documents, il est n√©c√©ssaire de distribuer son calcul. Nous allons pour cela d√©couper le travail en 3 √©tapes :\n",
    "\n",
    " + **1- Le calcul, pour chaque mot, de son nombre d'occurences par document.** Nous appelerons cette √©tape `WordFrequenceInDocs`.\n",
    " + **2- Le calcul du nombre de mots par documents**. Nous appelerons cette √©tape `WordCountsForDocs`.\n",
    " + **3- La combinaison des 2 informations pr√©c√©dentes pour calculer le TF_IDF**. Nous appelerons cette √©tape `WordsInCorpusTFIDF`.\n",
    " \n",
    "#### Etape 1 : WordFrequenceInDocs\n",
    "\n",
    "Il s'agit donc ici de formuler le probl√®me du calcul du nombre d'occurences des mots d'un document avec le cadre MapReduce. C'est un probl√®me tr√®s proche du probl√®me du WordCount vu en cours et rappel√© ci-dessus et vous devriez pouvoir y r√©pondre rapidement.\n",
    "\n",
    "**Donn√©es d'entr√©e**\n",
    "\n",
    "Votre premier travail est de proposer une repr√©sentation ad√©quate de vos donn√©es d'entr√©e (une collection de document) pour le cadre MapReduce. On consid√®re que chaque t√¢che `MAP` traitera un seul document (ou partie de document) et c'est donc ce document (ou cette partie) qui sera pris comme entr√©e de la fonction `MAP`.\n",
    "Que proposez-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4TwY_gfAlcD3"
   },
   "source": [
    "# A completer\n",
    "Un dictionnaire dont la cl√© est l'identifiant du document et le valeur est le document en soit (une string de texte par exemple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r63CLqfulcD8"
   },
   "source": [
    "**Fonction MAP**\n",
    "\n",
    "En vous inspirant du WordCount, √©crire en pseudo-code, la fonction MAP pour cette √©tape. Attention, il faudra pouvoir garder l'information relative √† l'identifiant du document consid√©r√©.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8-RW8iflcD9"
   },
   "outputs": [],
   "source": [
    "# A completer\n",
    "def my_map((doc_id, doc_content)):\n",
    "    tokens_count = []\n",
    "    for token in doc_content:\n",
    "        tokens_count.append((token, doc_id), 1)\n",
    "    return tokens_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gp3c-mGRlcEB"
   },
   "source": [
    "L'ensemble des paires (cl√©,valeur) provenant des diff√©rents noeuds `MAP` sont collect√©es et tri√©es par cl√©s interm√©diaires et donc fournies sous cette forme √† la t√¢che `REDUCE`. Ecrire, en pseudo-code la fonction `REDUCE` pour `WordFrequenceInDocs`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uYlPMXxwlcEE"
   },
   "outputs": [],
   "source": [
    "# A completer\n",
    "def my_reduce(tuple_word_doc_id, list_of_ones): #tuple_word_doc_id = (word, doc_id)\n",
    "    return (tuple_word_doc_id, len(list_of_ones)) #returns the term frequency of word in doc_id\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CY9qUu7elcEJ"
   },
   "source": [
    "#### Etape 2: WordCountsForDocs\n",
    "\n",
    "Il s'agit maintenant de calculer le nombre de mots par documents. Deux petites indications :\n",
    "+ L'entr√©e de cette t√¢che sera la sortie de la t√¢che pr√©c√©dente soit une paire de type \n",
    "`((word,doc_id),n)` avec `n` le nombre d'occurence du terme word dans le document `doc_id` soit le tf.\n",
    "+ Pour cette t√¢che, il pourrait √™tre int√©ressant de pouvoir avoir acc√®s aux documents par le m√©canisme (cl√©,valeur).\n",
    "\n",
    "Ecrire, en pseudo-code, la fonction `MAP`, puis la fonction `REDUCE` vous permettant de faire cette √©tape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMuX_wXjlcEK"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter\n",
    "#Map:\n",
    "def map_WordCountsForDocs(tuple,n): #tuple = (word,doc_id)\n",
    "    my_dict = {}\n",
    "    my_dict[doc_id] = n\n",
    "    return my_dict\n",
    "\n",
    "#Reduce:\n",
    "def reduce_WordCountsForDocs(doc_id, list_of_counts):\n",
    "    return (doc_id, sum(list_of_counts)) #return the number of words in doc_id\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwO0KHntlcEQ"
   },
   "source": [
    "#### Etape 3: WordsInCorpusTFIDF\n",
    "\n",
    "Il s'agit maintenant de combiner les informations pr√©c√©dentes pour calculer le TF-IDF pour chaque terme. On consid√®re √† nouveau ici que l'entr√©e est la sortie de la t√¢che pr√©c√©dente soit une paire de type \n",
    "`((word,doc_id),n/N)` avec `n` le nombre d'occurence du terme word dans le document `doc_id` et `N` le nombre total de mots dans le document `doc_id`. On supposera aussi que le nombre de documents $D$ dans la collection est pass√© au syst√®me sous la forme d'une constante.\n",
    "\n",
    "Ecrire, en pseudo-code, la fonction `MAP`, puis la fonction `REDUCE` vous permettant de faire cette √©tape.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3TNT6rklcES"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter\n",
    "def map_WordsInCorpusTFIDF( tuple, r): #tuple = (word,doc_id), r = n/N\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6wOI-1LqlcEV"
   },
   "source": [
    "### A la maison :  Construction d'un index invers√© en MapReduce\n",
    "\n",
    "Il s'agit ici de refl√©chir √† comment un index invers√© de documents peut √™tre construit de mani√®re distribu√©e √† l'aide de MapReduce. \n",
    "\n",
    "1. Ecrivez en pseudo-code la fonction `MAP` en pr√©cisant bien le type des donn√©es d'entr√©e.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgE8CAITlcEW"
   },
   "outputs": [],
   "source": [
    "# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8HXQ3WwrlcEa"
   },
   "source": [
    "2. Ecrivez en pseudo-code la fonction `REDUCE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XszSQNXXlcEc"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hjucRujolcEf"
   },
   "source": [
    "3. Un test sur machine\n",
    "\n",
    "Pour vous permettre de mettre en oeuvre ce m√©canisme de mani√®re concr√®te, vous allez appliquer cela √† l'indexation d'une collection [books.json](../Data/books.json).\n",
    "On cherche √† produire un fichier invers√© qui indique pour chaque mot, la liste des livres dans lesquels il appara√Æt en utilisant le cadre MapReduce.\n",
    "\n",
    "Pour cela, nous vous fournissons dans le r√©pertoire [Utils](./Utils) un fichier [Lab4.py](./Utils/Lab4.py) qui contient un ensemble de fonctions qui vous seront utiles.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vpIj2RZ7lcEg"
   },
   "source": [
    "Importer les fonctions utiles de ce module python √† l'aide de la commande ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0UOvVpRPlcEi"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab4 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cunk9SnklcEl"
   },
   "source": [
    "A l'aide de la fonction `readData(filename)` de ce module, charger le fichier [books.json](../Data/books.json)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYet4x_YlcEn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LkKMV_E9lcEq"
   },
   "source": [
    "Ecrire la fonction `mapper` n√©cessaire √† la construction de l'index invers√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wc-TZ3OklcEr"
   },
   "outputs": [],
   "source": [
    "def mapper(data):\n",
    "    # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "irozkNzrlcEw"
   },
   "source": [
    "Ecrire la fonction `reducer` n√©cessaire √† la construction de l'index invers√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oSsoq9SflcEx"
   },
   "outputs": [],
   "source": [
    "def reducer(data): \n",
    "    # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A88IjY5qlcEz"
   },
   "source": [
    "Tester vos deux fonctions en appliquant le code ci-dessous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QqcKWR75lcE0"
   },
   "outputs": [],
   "source": [
    "def invertedIndexExample(filename):\n",
    "    m = MapReduce(mapper, reducer)\n",
    "    results = m(readData(filename))\n",
    "    for w, b in results:\n",
    "        print(\"mot : \", w, \"livres : \", b)\n",
    "    return\n",
    "    \n",
    "invertedIndexExample('./Data/books.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bs8ftnbllcE2"
   },
   "source": [
    "## PARTIE 2 : Algorithme de PageRank\n",
    "\n",
    "Dans cette partie nous allons impl√©menter et √©tudier l'algorithme d'ordonnancement PageRank. Ce dernier est utilis√© par le moteur de recherche Google pour attribuer un score d'importance √† chaque page Web. D'ailleurs, c'est en partie sur la base de ce score (et de nombreux autres facteurs) que le moteur de recherche classe par ordre d'importance les pages Web correspondant √† une recherche donn√©e.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1gL0RatlcE4"
   },
   "source": [
    "### Le format des donn√©es\n",
    "\n",
    "Nous allons utiliser le format de type \"graphe\" pour repr√©senter un nombre $N$ de page Web. Voici un exemple de graphe :\n",
    "\n",
    "<img src=\"./Figures/graph.png\" width=\"500\" height=\"500\" />\n",
    "\n",
    "La premi√®re ligne indique le nombre de pages Web dont il est question pour le graphe. Puis pour chacune des lignes suivantes le premier num√©ro d√©finit l'identifiant d'une page et les num√©ros suivants les liens sortants de cette page. \n",
    "\n",
    "Vous disposez dans le dossier [Data](./Data) associ√© √† ce Lab de plusieurs graphes de tailles diff√©rentes.\n",
    "\n",
    "Comme nous allons manipuler des matrices dans cette partie, nous utiliserons la biblioth√®que numpy que vous pouvez installer avec la commande ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SElo29uIlcE5"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Nd7IAcplcE8"
   },
   "source": [
    "#### Premi√®re √©tape : Matrice d'Adjacence.\n",
    "\n",
    "Nous nommons $A$ matrice d'adjacence, la matrice de dimension $N \\times N$ telle que $a_{i,j}=1$ s'il existe un lien de la page $i$ vers la page $j$, et $0$ sinon.\n",
    "\n",
    "\n",
    "**1. Ecrire une fonction `build_adjacency_matrix(filename)` permettant de construire la matrice d'adjacence √† partir d'un graphe dont le format est d√©fini plus haut (et au format .txt).**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "with open('./Data/graph1.txt', 'r') as f:\n",
    "    N = f.readline()\n",
    "    line = f.readline().split()\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjacency_matrix = np.zeros((2,2))\n",
    "adjacency_matrix\n",
    "adjacency_matrix[0,0] = 1\n",
    "adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_N0La_ClcE-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_adjacendy_matrix(filename):\n",
    "    \"\"\"Build the adjacency matrix from the graph file\"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        N = int(f.readline())\n",
    "        adjacency_matrix = np.zeros((N,N))\n",
    "        for _ in range(N):\n",
    "            line = f.readline().split()\n",
    "            depart = int(line.pop(0))\n",
    "            for column in line:\n",
    "                adjacency_matrix[depart,int(column)] = 1\n",
    "        return adjacency_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "80tBTvC_lcFB"
   },
   "source": [
    "**2. Ouvrir le graph1.txt pr√©sent dans le dossier Data et dessiner le √† la main avec des noeuds portant les num√©ros de pages et des fl√®ches repr√©sentant les liens.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yXAAVtcplcFE"
   },
   "source": [
    "**3. Appliquer la fonction `build_adjacency_matrix()` au graph1.txt pr√©sent dans le dossier Data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQdhxacnlcFG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 0., 1., 1., 1.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_adjacendy_matrix('./Data/graph1.txt')# A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XVxCBe6ylcFJ"
   },
   "source": [
    "#### Deuxi√®me  √©tape : Matrice de transition.\n",
    "\n",
    "A partir de la matrice d'adjacence, il est possible de calculer une matrice de transition $P$ de param√®tre $\\lambda$ dont nous aurons besoin lors de l'impl√©mentation de l'algorithme de PageRank. La matrice de transition est d√©finie par :\n",
    "\n",
    "$$ P_{i,j} =  \\left\\{\n",
    "\\begin{array}{l}\n",
    "   \\left.\\begin{array}{l} \n",
    "   \\lambda \\frac{a_{i,j}}{\\sum_{j=1}^N a_{i,j}} + (1-\\lambda ) \\frac{1}{N}  \\text{ si} \\sum_{j=1}^N a_{i,j} \\neq 0\\\\\n",
    "   \\frac{1}{N} \\text{ sinon.}\\\\\n",
    "   \\end{array}\\right.  \\\\\n",
    "\\end{array}\n",
    "\\right.$$\n",
    "\n",
    "\n",
    "**4.  Ecrire une fonction `build_transition_matrix(filename, lam)` permettant de construire la matrice de transition √† partir d'un graph (au format .txt) et d'une valeur pour le param√®tre $\\lambda$ (correspondant √† lam car lambda est un mot cl√© du langage python).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros((3,3))\n",
    "x\n",
    "len(x)\n",
    "list(range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35., 35., 35.],\n",
       "       [ 0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:] = 1\n",
    "x\n",
    "x[0,:] = x[0,:]/2\n",
    "x[0,:] = x[0,:]*10 + 30\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_vZGjuI1lcFJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_transition_matrix(filename, lam):\n",
    "    \"\"\"Build the transition matrix from the adjacency matrix\"\"\"\n",
    "    # A completer\n",
    "    adjacency_matrix = build_adjacendy_matrix(filename)\n",
    "    N = len(adjacency_matrix)\n",
    "    for line in range(N):\n",
    "        somme = sum(adjacency_matrix[line,:])\n",
    "        if somme != 0:\n",
    "            adjacency_matrix[line,:] = (lam/somme)*adjacency_matrix[line,:] + (1-lam)/N\n",
    "        else:\n",
    "            adjacency_matrix[line,:] = 1/N\n",
    "        \n",
    "    return adjacency_matrix\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKu2Ux72lcFO"
   },
   "source": [
    "**5. Appliquer cette fonction au graph1.txt pr√©sent dans le dossier Data pour une valeur de lambda de 0.85 (valeur habituellement choisie).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7uVT6lBlcFO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.025     , 0.025     , 0.45      , 0.45      , 0.025     ,\n",
       "        0.025     ],\n",
       "       [0.30833333, 0.025     , 0.025     , 0.30833333, 0.025     ,\n",
       "        0.30833333],\n",
       "       [0.025     , 0.2375    , 0.025     , 0.2375    , 0.2375    ,\n",
       "        0.2375    ],\n",
       "       [0.875     , 0.025     , 0.025     , 0.025     , 0.025     ,\n",
       "        0.025     ],\n",
       "       [0.025     , 0.025     , 0.025     , 0.875     , 0.025     ,\n",
       "        0.025     ],\n",
       "       [0.025     , 0.025     , 0.45      , 0.45      , 0.025     ,\n",
       "        0.025     ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_transition_matrix(('./Data/graph1.txt'), 0.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xpOdgiM3lcFR"
   },
   "source": [
    "**6. Appliquer la fonction somme sur les colonnes de la matrice de transition $P$ (sommes de tous les √©l√©ments d'une ligne, ligne par ligne). Que constatez-vous ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RxHVFWC_lcFT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A completer\n",
    "transition_matrix = build_transition_matrix(('./Data/graph1.txt'), 0.85)\n",
    "transition_matrix.sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8QwfJxallcFW"
   },
   "source": [
    "**Interpretation de la matrice de transition**\n",
    "\n",
    "Le PageRank simule le chemin al√©atoire d'un internaute qui naviguerait sur le Web en choisissant au hasard les liens √† suivre sur une page donn√©e. Par exemple, dans le cas de la figure plus haut (en section intitul√©e \"le format des donn√©es\"), un internaute situ√© en page 1 choisirait d'aller √† la page 0, 3 ou 2 avec probabilit√© 1/3, 1/3, 1/3 car il y a trois liens sortants de la page 1. Les √©l√©ments de la matrice de transition repr√©sentent en effet des probabilit√©s de transition √† chaque n≈ìud qui peuvent √™tre d√©crites globalement par la matrice de transition $P$ de dimension $N\\times N$, o√π $N$ est le nombre de n≈ìuds dans le graphique et l'√©l√©ment $p_{ùëñ, ùëó}$ est la probabilit√© qu'un internaute al√©atoire passe de la page $i$ √† la page $j$.\n",
    "\n",
    "\n",
    "**7. Dans le cas du graph1.txt, selon votre lecture visuelle du graph1 quelles sont les probabilit√©s d'un internaute situ√© en page 5 d'aller dans chacunes des autres pages web ? Et selon votre matrice de transition, quelles sont ces m√™mes probabilit√©s ? Que constatez vous ?**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t4sorE-3lcFW"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter\n",
    "# He can go to either page 2 or 3 with probability 1/2. In the transition matrix we take into account the probability\n",
    "# that the user \"jumps\" to any other page with a small probability 0,025."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "swRLG-F4lcFb"
   },
   "source": [
    "**8. Calculer √† nouveau la matrice de transition avec $\\lambda=1$. Que constatez-vous ? Nous reviendrons sur l'√©tude du param√®tre $\\lambda$ et de son r√¥le par la suite.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaAR-J6ElcFb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.5       , 0.5       , 0.        ,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.        , 0.        , 0.33333333, 0.        ,\n",
       "        0.33333333],\n",
       "       [0.        , 0.25      , 0.        , 0.25      , 0.25      ,\n",
       "        0.25      ],\n",
       "       [1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.5       , 0.5       , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_matrix = build_transition_matrix(('./Data/graph1.txt'), 1)\n",
    "transition_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8V6yKdflcFd"
   },
   "source": [
    "En parcourant plusieurs fois des balades al√©atoires sur le graphe, PageRank simule le comportement de plusieurs internautes al√©atoires. Les pages qui re√ßoivent un plus grand nombre de visites sont consid√©r√©es comme plus importantes que celles qui ne le sont que rarement. \n",
    "\n",
    "\n",
    "Notons qu'au d√©part, quand un internaute commence sa promenade, il peut √™tre n'importe o√π dans le graphe. Si nous n'avons aucune raison de penser qu'il serait plus susceptible de choisir une page plus qu'une autre comme point de d√©part, nous pouvons dire que la probabilit√© initiale que l'internaute se trouve sur une certaine page est √©gale √† $\\frac{1}{N}$.\n",
    "\n",
    "Ainsi, au d√©part, la distribution de probabilit√© de la position de l'internaute peut √™tre d√©crite par un vecteur colonne $R^{(0)}$ avec $N$ √©l√©ments prenant pour valeur $\\frac{1}{N}$. Ce vecteur s'appelle le vecteur PageRank √† l'it√©ration initiale $l=0$. Pour une it√©ration quelconque nous le noterons $l$.\n",
    "\n",
    "\n",
    "#### Troisi√®me  √©tape : Algorithme de PageRank\n",
    "\n",
    "Nous avons √† ce moment en notre possession l'ensemble des √©l√©ments et outils pour impl√©menter facilement l'algorithme de PageRank suivant :\n",
    "\n",
    "<img src=\"./Figures/Algo_PR.png\" width=\"700\" height=\"700\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8iqzzKfklcFe"
   },
   "source": [
    "**9. Impl√©menter l'Algorithme 1 par une fonction `page_rank(transition_matrix, epsilon = 1e-3):` en r√©utilisant toutes les fonctions que vous venez de construire plus haut et en fixant tout d'abord $\\lambda=0.85$. Attention : dans la partie initialisation, pensez √† initialiser l'erreur $\\epsilon$, par exemple √† la valeur $1$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667],\n",
       "       [0.16666667]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([3,4])\n",
    "x \n",
    "np.linalg.norm(x)\n",
    "N = 6\n",
    "R_1 = np.full((N, 1), 1/N)\n",
    "R_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QH1rg0bilcFf"
   },
   "outputs": [],
   "source": [
    "def page_rank(transition_matrix, epsilon=1):\n",
    "    \"\"\"Run the PageRank algorithm based on the transition matrix\"\"\"\n",
    "    N = len(transition_matrix)\n",
    "    R_1 = np.full((1, N), 1/N)\n",
    "    R_2 = np.dot(R_1, transition_matrix)\n",
    "    l = 0\n",
    "    while np.linalg.norm(R_2 - R_1) > epsilon:\n",
    "        l += 1\n",
    "        R_1 , R_2 = R_2, np.dot(R_2, transition_matrix)\n",
    "    #print(np.sum(R_1))\n",
    "    print('number of iterations for epsilon = {} : {}'.format(epsilon, l))\n",
    "    return R_1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fuD3Up4rlcFh"
   },
   "source": [
    "**10. Appliquez l'algorithme 1 au graph1.txt avec $\\lambda=0.85$ et $\\epsilon = 10^{-3}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tJqzm-VlcFh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of iterations for epsilon = 0.0001 : 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29902267, 0.06483634, 0.18740393, 0.30069957, 0.06483634,\n",
       "        0.08320116]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_rank(build_transition_matrix(('./Data/graph1.txt'), 0.85), 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XcenhQKXlcFk"
   },
   "source": [
    "#### Quatri√®me √©tape : Etude et analyse de l'algorithme de PageRank impl√©ment√©.\n",
    "\n",
    "Rappel : fixez tout d'abord $\\lambda=0.85$.\n",
    "\n",
    "**11. Choisissez diff√©rentes valeurs pour le crit√®re d'arr√™t telles que $\\epsilon = {10^{-3}, 10^{-4}, 10^{-5}}$. Qu'est-ce que vous observez ?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "db8Lx6t8lcFl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For e = 10-3: [[0.29935795 0.06491206 0.18716453 0.30040839 0.06491206 0.08324501]]\n",
      "For e = 10-4: [[0.29902267 0.06483634 0.18740393 0.30069957 0.06483634 0.08320116]]\n",
      "For e = 10-5: [[0.29899138 0.06482929 0.18742625 0.3007267  0.06482929 0.08319708]]\n"
     ]
    }
   ],
   "source": [
    "# A compl√©ter\n",
    "print('For e = 10-3:', page_rank(build_transition_matrix(('./Data/graph1.txt'), 0.85), 0.001))\n",
    "print('For e = 10-4:', page_rank(build_transition_matrix(('./Data/graph1.txt'), 0.85), 0.0001))\n",
    "print('For e = 10-5:',  page_rank(build_transition_matrix(('./Data/graph1.txt'), 0.85), 0.00001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIefxWjOlcFn"
   },
   "source": [
    "**12. Ajouter quelques hubs (pages qui ont beaucoup de liens sortant) et autorit√©s (pages qui ont beaucoup de liens entrant). Quelles pages sont class√©es le plus haut ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-h_62AylcFn"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z9mlHHa0lcFp"
   },
   "source": [
    "**13. Essayez d‚Äôaccro√Ætre les rangs de certaines pages. Expliquez votre m√©thode et validez-la exp√©rimentalement.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7DuV0OQPlcFq"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p98pkvOilcFs"
   },
   "source": [
    "**14. Essayez diff√©rentes valeurs pour le facteur d‚Äôamortissement $\\lambda$. Quel est le comportement de l‚Äôalgorithme lorsque $\\lambda$ tend vers 0 ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o2fZGERlcFs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zIlwE5A4lcFu"
   },
   "source": [
    "**15. (√Ä la maison) Amusez vous √† tester l'algorithme sur les autres graphes plus volumineux mis √† votre disposition dans le dossier Data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OdlLVeC3lcFu"
   },
   "outputs": [],
   "source": [
    "# A compl√©ter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cqqdYWDhlcFw"
   },
   "source": [
    "## PARTIE 3 : PageRank en mode distribu√©\n",
    "\n",
    "Nous allons nous int√©resser ici au passage √† l'√©chelle du page rank pour permettre de traiter les cas des graphes tr√®s volumineux comme le web.\n",
    "\n",
    "Vous devez avoir bien compris le principe de cet algoritme maintenant et votre premier travail sera donc d'appliquer le cadre MapReduce au calcul du PageRank. Dans un premier temps, vous pourrez ne pas prendre en compte le m√©canisme de t√©l√©transportation pour vous faciliter la t√¢che.\n",
    "\n",
    "**1. Un exemple de graphe**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COrb1KHHlcFx"
   },
   "source": [
    "Pour vous aider, vous pouvez vous aider d'un exemple de graphe simple comme celui ci-dessous. \n",
    "\n",
    "<img src=\"./Figures/graphes_lin.png\" width=\"700\" height=\"700\" />\n",
    "\n",
    "Source : Lin - Data-Intensive Text Processing with MapReduce\n",
    "\n",
    "\n",
    "A partir de cet exemple, pour vous aider √† √©crire votre fonction `map`, essayer de r√©flechir √† comment le calcul du page rank transforme les diff√©rents noeuds √† chaque it√©ration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p9PX3Y1blcFy"
   },
   "source": [
    "**2. Proposez en pseudo code un algorithme Mapeduce pour le calcul du PageRank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cndOw1kElcFy"
   },
   "outputs": [],
   "source": [
    "# A completer"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_4_MapR_PR_Student.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
